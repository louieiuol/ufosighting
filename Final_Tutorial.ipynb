{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO Sightings Through the Data Science Pipeline \n",
    "\n",
    "By Melissa Chen and Andrea Soto\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Most of us do not realize that data science plays a role in various aspects of our daily lives. For example, data sience can have applications in the areas of marketing and advertising, healthcare, government, image recognition, cybersecuirty and many more. Data science is a rapidly rising, interdisciplinary field that involves an understanding of various scientific, mathematical, computational and design techniques in order to extract insight from large amounts of data to solve real world problems. More and more industries are noticing the importance of this field for making smart, informed, and even profitable everyday decisions. Since there is an increasing need for knowledgeable and able data scientists, it is important for more people to acquire the necessary skills so that they can confidently enter this exciting and growing field. \n",
    "\n",
    "In this introductory tutorial we will choose a dataset and walk through the steps of the data science pipeline in manner that is easy to understand and follow. The pipeline consists of the following steps: \n",
    "\n",
    "1. Data Collection \n",
    "2. Data Processing \n",
    "3. Exploratory Analysis and Visualization \n",
    "4. Hypothesis Testing and Machine Learning \n",
    "5. Insight and Policy \n",
    "\n",
    "This tutorial can help those with an understanding of scripting languages but who are new to the data science methodology as a whole. It can also help more experieced data scientists who are perhaps unfamiliar with Python and the various libraries availble that simplify the data analysis process.\n",
    "\n",
    "By the end of the tutorial, you will have learned how to search for and derive meaningful information from a large dataset and convey your findings in a visually, insightful way.\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "1. [Lab Set-Up](#lab)\n",
    "2. [Motivation](#mot)\n",
    "3. [Data Collection](#coll)\n",
    "4. [Data Processing](#proc)\n",
    "5. [Exploratory Analysis and Visualization](#expl)\n",
    "6. [Hypothesis Testing and Machine Learning](#hyp)\n",
    "7. [Insights](#ins)\n",
    "8. [Summary](#sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Set-Up\n",
    "<a id='lab'></a>\n",
    "\n",
    "First we need to set up your machine. The easiest way to do this is to download [Anaconda](https://www.anaconda.com/download/#macos), a popular Python data science platform, with Python version 3.6. We recommend using [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/) to create documents where you can run your code and easily view data visualizations. This open-source application makes it especially easy for beginners to learn and comes with the Anaconda package. Simply run the command `jupyter notebook` in the OSX/Linux terminal or Windows Command Prompt to launch the Jupyter interface. Jupyter allows the use of [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) language to easily document your code and make your documents more presentable. \n",
    "\n",
    "Create a new directory for this tutorial and within it, create a jupyter notebook and download the [UFO Sightings](https://www.kaggle.com/NUFORC/ufo-sightings/) dataset. We will be using the following Python libraries:\n",
    "\n",
    "1. [Pandas](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "2. [Numpy](https://docs.scipy.org/doc/numpy/)\n",
    "3. [Matplotlib](https://matplotlib.org/)\n",
    "4. [Seaborn](https://seaborn.pydata.org/)\n",
    "5. [sklearn](http://scikit-learn.org/stable/)\n",
    "6. [Folium](https://github.com/python-visualization/folium)\n",
    "\n",
    "Folium is not included with the Anaconda package so you will have to install it by running the `pip install folium` command in the terminal/command prompt. Below shows the proper way to import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as skl\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "<a id='mot'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "<a id='coll'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
